{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fa4865e",
   "metadata": {},
   "source": [
    "PREPROCESSING AND STACKING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0991f8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import SimpleITK as sitk # Loading, saving, and converting medical images\n",
    "from monai.transforms import (\n",
    "    LoadImaged, EnsureChannelFirstd, ConcatItemsd,\n",
    "    NormalizeIntensityd, Spacingd, CropForegroundd,\n",
    "    Resized, Compose, SaveImaged\n",
    ")\n",
    "from monai.data import Dataset\n",
    "import torch\n",
    "from monai.transforms import Resize\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d658fd16",
   "metadata": {},
   "source": [
    "Preprocessing Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ab903a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "brats_root = Path(r\"C:/Users/user/NeuroSegNet/data/raw/BraTS2025-GLI-PRE-Challenge-TrainingData/BraTS2025-GLI-PRE-Challenge-TrainingData\")\n",
    "output_dir = Path(\"data/processed_stacked/\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "modalities = [\"t1n\", \"t1c\", \"t2w\", \"t2f\"]\n",
    "print(f\"Path exists: {brats_root.exists()}\")\n",
    "print(f\"Sample folders: {[p.name for p in brats_root.glob('*')][:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a57a99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build MONAI transform pipeline\n",
    "modality_keys = [f\"image-{mod}\" for mod in modalities]\n",
    "\n",
    "preprocessing = Compose([\n",
    "    LoadImaged(keys=modality_keys),\n",
    "    EnsureChannelFirstd(keys=modality_keys),\n",
    "    ConcatItemsd(keys=modality_keys, name=\"image\", dim=0),  # Combine into (4, H, W, D)\n",
    "    NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "    Spacingd(keys=\"image\", pixdim=(1.0, 1.0, 1.0), mode=\"bilinear\"),\n",
    "    CropForegroundd(keys=\"image\", source_key=\"image\"),\n",
    "    Resized(keys=\"image\", spatial_size=(128, 128, 128)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84567ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust Preprocessing Loop with Debug Prints\n",
    "from monai.transforms import Resize\n",
    "\n",
    "processed = 0\n",
    "patients = sorted(list(brats_root.glob(\"BraTS-GLI-*\")))\n",
    "\n",
    "for patient_path in tqdm(patients, desc=\"Preprocessing & Stacking Patients\"):\n",
    "    patient_id = patient_path.name.strip()\n",
    "    data = {}\n",
    "    missing = False\n",
    "\n",
    "    for mod in modalities:\n",
    "        expected_file = patient_path / f\"{patient_id}-{mod}.nii.gz\"\n",
    "        if not expected_file.exists():\n",
    "            print(f\"[Missing] {expected_file.name} in {patient_path}\")\n",
    "            missing = True\n",
    "            break\n",
    "        data[f\"image-{mod}\"] = str(expected_file)\n",
    "\n",
    "    seg_path = patient_path / f\"{patient_id}-seg.nii.gz\"\n",
    "    if not seg_path.exists():\n",
    "        print(f\"[Missing Segmentation] {seg_path}\")\n",
    "        missing = True\n",
    "\n",
    "    if missing:\n",
    "        continue\n",
    "\n",
    "    dataset = Dataset(data=[data], transform=preprocessing)\n",
    "\n",
    "    try:\n",
    "        img_tensor = dataset[0][\"image\"]  # [4, H, W, D]\n",
    "        img_tensor = img_tensor.unsqueeze(0).float()  # [1, 4, H, W, D]\n",
    "\n",
    "        # Load segmentation\n",
    "        seg = nib.load(str(seg_path))\n",
    "        seg_data = seg.get_fdata()\n",
    "        seg_tensor = torch.tensor(seg_data).unsqueeze(0).unsqueeze(0).float()  # [1, 1, H, W, D]\n",
    "\n",
    "        # Resize seg if needed\n",
    "        if seg_tensor.shape[2:] != img_tensor.shape[2:]:\n",
    "            resize = Resize(spatial_size=img_tensor.shape[2:], mode=\"nearest\")\n",
    "            seg_tensor = resize(seg_tensor.squeeze(0)).unsqueeze(0)\n",
    "\n",
    "        # Stack into [5, H, W, D]\n",
    "        stacked_tensor = torch.cat([img_tensor, seg_tensor], dim=1).squeeze(0)  # [5, H, W, D]\n",
    "        stacked_data = np.moveaxis(stacked_tensor.numpy(), 0, -1)  # [H, W, D, 5]\n",
    "\n",
    "        # Save only stacked file\n",
    "        stacked_path = output_dir / f\"{patient_id}_ground_truth.nii.gz\"\n",
    "        nib.save(nib.Nifti1Image(stacked_data, affine=np.eye(4)), str(stacked_path))\n",
    "        processed += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] {patient_id}: {e}\")\n",
    "\n",
    "print(f\"Successfully processed & stacked {processed} patients. Saved only to {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48e6594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a sample saved 4-channel volume\n",
    "saved_files = sorted(output_dir.glob(\"*.nii.gz\"))\n",
    "print(f\"Files saved: {[f.name for f in saved_files]}\")\n",
    "print(f\"Total saved: {len(saved_files)}\")\n",
    "\n",
    "# Only proceed if something was saved\n",
    "if saved_files:\n",
    "    sample_file = saved_files[0]\n",
    "    img = nib.load(sample_file).get_fdata()\n",
    "    img = np.transpose(img, (3, 0, 1, 2))  # (C, H, W, D)\n",
    "    print(f\"Loaded {sample_file.name}, new shape after transpose: {img.shape}\")\n",
    "\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    for i in range(4):\n",
    "        axes[i].imshow(img[i, :, :, img.shape[3] // 2], cmap='gray')\n",
    "        axes[i].set_title(modalities[i])\n",
    "        axes[i].axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No preprocessed images found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1f79a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the stacked data \n",
    "stacked_dir = Path(\"../data/processed_stacked\")\n",
    "\n",
    "# Load stacked files\n",
    "stacked_files = sorted(stacked_dir.glob(\"*.nii.gz\"))\n",
    "print(f\"Stacked files found: {len(stacked_files)}\")\n",
    "\n",
    "if stacked_files:\n",
    "    # Load one stacked volume: [H, W, D, 5]\n",
    "    img = nib.load(stacked_files[0]).get_fdata()\n",
    "    img = np.transpose(img, (3, 0, 1, 2))  # [5, H, W, D]\n",
    "    \n",
    "    # Extract segmentation channel\n",
    "    seg_channel = img[4]\n",
    "    print(\"Segmentation unique values:\", np.unique(seg_channel))\n",
    "    print(\"Segmentation min/max:\", seg_channel.min(), seg_channel.max())\n",
    "\n",
    "    # === Visualization ===\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(25, 5))\n",
    "    mid_slice = img.shape[3] // 2  # Mid axial slice\n",
    "\n",
    "    for i in range(5):\n",
    "        slice_img = img[i, :, :, mid_slice]\n",
    "        if i < 4:\n",
    "            axes[i].imshow(slice_img, cmap=\"gray\")\n",
    "            axes[i].set_title(f\"Modality {i + 1}\", fontsize=12)\n",
    "        else:\n",
    "            axes[i].imshow(\n",
    "                slice_img,\n",
    "                cmap=\"gray\",\n",
    "                vmin=0,\n",
    "                vmax=np.max(seg_channel),\n",
    "                interpolation=\"nearest\"\n",
    "            )\n",
    "            axes[i].set_title(\"Segmentation\", fontsize=12)\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    plt.suptitle(f\"{stacked_files[0].name} - Mid-slice preview\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"No stacked volumes found in:\", stacked_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc06c7db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a952ec1",
   "metadata": {},
   "source": [
    "Preprocessing Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7231f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "val_root = Path(r\"C:/Users/user/NeuroSegNet/data/raw/BraTS2025-GLI-PRE-Challenge-ValidationData/BraTS2025-GLI-PRE-Challenge-ValidationData\")\n",
    "\n",
    "output_dir = Path(\"data/val_preprocessed/\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "modalities = [\"t1n\", \"t1c\", \"t2w\", \"t2f\"]\n",
    "print(f\"Path exists: {val_root.exists()}\")\n",
    "print(f\"Sample folders: {[p.name for p in val_root.glob('*')][:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c5331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new preprocessing pipeline for validation data\n",
    "modality_keys = [f\"image-{mod}\" for mod in modalities]\n",
    "preprocessing_val = Compose([\n",
    "    LoadImaged(keys=modality_keys),\n",
    "    EnsureChannelFirstd(keys=modality_keys),\n",
    "    ConcatItemsd(keys=modality_keys, name=\"image\", dim=0),\n",
    "    NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "    Spacingd(keys=\"image\", pixdim=(1.0, 1.0, 1.0), mode=\"bilinear\"),\n",
    "    CropForegroundd(keys=\"image\", source_key=\"image\"),\n",
    "    Resized(keys=\"image\", spatial_size=(128, 128, 128)),\n",
    "    SaveImaged(keys=\"image\", output_dir=output_dir, output_postfix=\"norm\", separate_folder=False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814a6597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Loop with Debug Prints\n",
    "processed = 0\n",
    "patients = sorted(list(val_root.glob(\"BraTS-GLI-*\")))\n",
    "\n",
    "for patient_path in tqdm(patients, desc=\"Preprocessing Val MRI\"):\n",
    "    patient_id = patient_path.name.strip()  # strip whitespace\n",
    "    data = {}\n",
    "    missing = False\n",
    "\n",
    "    for mod in modalities:\n",
    "        expected_file = patient_path / f\"{patient_id}-{mod}.nii.gz\"\n",
    "        \n",
    "        if not expected_file.exists():\n",
    "            # Print all files in the folder if missing\n",
    "            available = list(patient_path.glob(\"*.nii.gz\"))\n",
    "            print(f\"[Missing] Expected: {expected_file.name} in {patient_path}\")\n",
    "            print(f\"Available files: {[f.name for f in available]}\")\n",
    "            missing = True\n",
    "            break\n",
    "        else:\n",
    "            data[f\"image-{mod}\"] = str(expected_file)\n",
    "\n",
    "    if missing:\n",
    "        continue\n",
    "\n",
    "    dataset = Dataset(data=[data], transform=preprocessing_val)\n",
    "\n",
    "    try:\n",
    "        _ = dataset[0]\n",
    "        processed += 1\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] {patient_id}: {e}\")\n",
    "\n",
    "print(f\"Successfully processed {processed} 4-channelled val MRI.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c67eabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessed 4-channel validation MRI modalities volume to disk\n",
    "output_dir = Path(\"../data/val_preprocessed\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for patient_path in tqdm(patients, desc=\"Saving preprocessed volumes\"):\n",
    "    patient_id = patient_path.name.strip()\n",
    "    data = {}\n",
    "    missing = False\n",
    "\n",
    "    for mod in modalities:\n",
    "        expected_file = patient_path / f\"{patient_id}-{mod}.nii.gz\"\n",
    "        if not expected_file.exists():\n",
    "            missing = True\n",
    "            break\n",
    "        else:\n",
    "            data[f\"image-{mod}\"] = str(expected_file)\n",
    "\n",
    "    if missing:\n",
    "        continue\n",
    "\n",
    "    dataset = Dataset(data=[data], transform=preprocessing_val)\n",
    "\n",
    "    try:\n",
    "        img = dataset[0][\"image\"]\n",
    "        img_np = img.numpy()  # shape (4, H, W, D)\n",
    "        img_np = np.transpose(img_np, (1, 2, 3, 0))  # (H, W, D, 4)\n",
    "\n",
    "        out_img = nib.Nifti1Image(img_np, affine=np.eye(4))\n",
    "        nib.save(out_img, output_dir / f\"{patient_id}_val_image.nii.gz\")\n",
    "        print(f\"Saved {patient_id}_val_image.nii.gz\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save {patient_id}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9928ff86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a sample saved multimodal mri preprocessed data\n",
    "saved_files = sorted(output_dir.glob(\"*.nii.gz\"))  # uses the same output_dir from cell 11\n",
    "print(f\"Files saved: {[f.name for f in saved_files[:5]]}\")\n",
    "print(f\"Total saved: {len(saved_files)}\")\n",
    "\n",
    "if saved_files:\n",
    "    sample_file = saved_files[0]\n",
    "    img = nib.load(sample_file).get_fdata()\n",
    "    img = np.transpose(img, (3, 0, 1, 2))  # (C, H, W, D)\n",
    "    print(f\"Loaded {sample_file.name}, new shape after transpose: {img.shape}\")\n",
    "\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    for i in range(4):\n",
    "        axes[i].imshow(img[i, :, :, img.shape[3] // 2], cmap='gray')\n",
    "        axes[i].set_title(modalities[i])\n",
    "        axes[i].axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"No preprocessed images found in {output_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain_mri_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
